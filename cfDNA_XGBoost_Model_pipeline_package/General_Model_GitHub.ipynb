{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Created by: Sakuntha Devaka Gunarathna /\n",
        "Published Date: July 30, 2025"
      ],
      "metadata": {
        "id": "o4Y_bBnksEeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install required dependencies\n",
        "pip install xgboost==2.0.3 scikit-learn==1.3.2 numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "id": "ohKbBtXeQqkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Load and manipulate data\n",
        "import numpy as np  # Calculate mean and standard deviation\n",
        "import xgboost as xgb  # XGBoost functionality\n",
        "import matplotlib.pyplot as plt  # Plotting\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split  # Split datasets\n",
        "from sklearn.metrics import (\n",
        "    balanced_accuracy_score,\n",
        "    roc_auc_score,\n",
        "    make_scorer,\n",
        "    confusion_matrix,  # Metrics\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV  # Grid search and cross-validation\n",
        "from xgboost import XGBClassifier, plot_importance, plot_tree  # XGBoost utilities\n",
        "from numpy import load"
      ],
      "metadata": {
        "id": "Ih_SgwMxU2W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"XGBoost version:\", xgb.__version__)\n",
        "print(\"Scikit-learn version:\", sklearn.__version__)\n",
        "print(\"Numpy version:\", np.__version__)"
      ],
      "metadata": {
        "id": "05V8LDgXXb7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label = pd.read_csv('Patient_ID.csv', index_col=\"Patient_ID\")\n",
        "#df_label.set_index('Patient_ID')\n",
        "df_label.head()"
      ],
      "metadata": {
        "id": "lBrWfjY93Tnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Index Column to List\n",
        "index_list = df_label.index.tolist()\n",
        "print(index_list)\n",
        "\n",
        "# col_list =  list(df_label[\"Patient_ID\"])\n",
        "# print(col_list)"
      ],
      "metadata": {
        "id": "op1HN9IJ9lvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the \"Reference_Peaks_ID.csv\" file which contain Referance_ID, Chromosome_Name, Begins,Ends and Fragment_Length.\n",
        "#Create new Dataframe\n",
        "df_ID = pd.read_csv('Reference_Peaks_ID.csv')\n",
        "df_ID.head()"
      ],
      "metadata": {
        "id": "r2qVT01Tfdrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAUPR1huaOrz"
      },
      "outputs": [],
      "source": [
        "#load \"Output_deepTools_multiBigwigSummary.npz\" to a object with the name \"data\".\n",
        "# \".npz\" must be generated with deeptools multiBigwigSummary using the same BED file coordinates as provided in \"Reference_Peaks_ID.csv\"\n",
        "#Reference Peak details should be given as a \".bed\" file for deeptools - multiBigwigSummary. eg: nohup multiBigwigSummary BED-file -b <path_to_bigwig_files_group1>/*.bw <path_to_bigwig_files_group2>/*.bw ... -o <output_results>.npz --outRawCounts <output_counts>.tab --BED <regions_file>.bed &\n",
        "\n",
        "data = load('Output_deepTools_multiBigwigSummary.npz')\n",
        "\n",
        "#List out and print all the variables and their content within the \"data\" object\n",
        "lst = data.files\n",
        "for item in lst:\n",
        "    print(item)\n",
        "    print(data[item])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the list of variables in \"data\" object\n",
        "print(lst)"
      ],
      "metadata": {
        "id": "Si9CFq8lae0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add data in to two separate variables\n",
        "# array_1 = data['labels'] #Array_1 contain label information\n",
        "\n",
        "array_1 = index_list #Array_1 contain label information taken from \"df_label\" dataframe index column and stored in \"index_list\" variable.\n",
        "array_2 = data['matrix'] #Array_2 contain \"matrix\" variable information stored in \"data\" object."
      ],
      "metadata": {
        "id": "ww75jVqAaheV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(array_1)"
      ],
      "metadata": {
        "id": "NrqJyABRCDAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(array_2)"
      ],
      "metadata": {
        "id": "N_0Vx-BGao4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add \"data\" object \"array_2\" to a pandas dataframe.\n",
        "#column_names = ['column 1', 'column 2', 'column 3']\n",
        "\n",
        "column_names = array_1\n",
        "df_Original = pd.DataFrame(array_2, columns=column_names)\n",
        "print(df_Original)"
      ],
      "metadata": {
        "id": "W772mHZqaqA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To save the dataframe to .CSV file\n",
        "df_Original.to_csv('General_MODEL_Original.csv', index=False)"
      ],
      "metadata": {
        "id": "6EiVJ_ZYaxzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Join(Concatanate) \"df_ID\" dataframe with \"df_Original\" dataframe.\n",
        "df_1 = pd.concat([df_ID, df_Original], axis=1)\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "Fqa3EB3-mZaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the names of the columns.\n",
        "print(df_1.columns)"
      ],
      "metadata": {
        "id": "nz-dI0lliQqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the shape of the dataset.\n",
        "print(df_1.shape)"
      ],
      "metadata": {
        "id": "up4m6PRSilsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop rows containg \"Chr Y\" information\n",
        "#df_1.drop(df_1.loc[df_1['Chromosome_Name']=='chrY'].index, inplace=True)\n",
        "#df_1.drop(df_1.loc[df_1['Chromosome_Name']=='chrX'].index, inplace=True)"
      ],
      "metadata": {
        "id": "W39Zq1Nc4SEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop rows containg \"ChrM\", \"Random Chr\", \"Unmapped Chr\". This code will keep all rows in df_1 where the 'Chromosome_Name' does NOT contain any of the specified keywords.\n",
        "keywords = [\"chrUn\", \"chrM\", \"random\"]\n",
        "df_1 = df_1[~df_1['Chromosome_Name'].str.contains('|'.join(keywords))]"
      ],
      "metadata": {
        "id": "aEogty-SqyNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the shape of the dataset.\n",
        "print(df_1.shape)"
      ],
      "metadata": {
        "id": "55ewczgQ6-Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set axis=0 to remove rows, axis = 1 to remove colums.\n",
        "#Inplace=True will save the changers in to the df dataframe directly without making a copy.\n",
        "#df_1.columns = df_1.columns.str.replace(' ','_')\n",
        "\n",
        "#To drop columns\n",
        "df_1.drop(['Chromosome_Name','Begins','Ends','Fragment_Length'],axis=1, inplace=True)\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "Fn4yH5h4ir3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To get the data types\n",
        "df_1.dtypes"
      ],
      "metadata": {
        "id": "kfPHR2HDoH4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To transpose the data set (Rows to columns and columns to rows)\n",
        "#df = df.transpose()  => Will only transpose data but it will not set the \"Referance_ID\" as column names\n",
        "\n",
        "\n",
        "#Transpose Data Frame & Set First Column as Header\n",
        "#To transpose data and set the \"Referance_Id\" as column names.\n",
        "df_2 = df_1.set_index('Referance_ID').T\n",
        "df_2.head()"
      ],
      "metadata": {
        "id": "pknAL0tkrxLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To get the data types\n",
        "df_2.dtypes"
      ],
      "metadata": {
        "id": "jcj79JGFlFD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To save the transposed data set\n",
        "df_2.to_csv('General_MODEL_Transposed.csv', index= False)\n",
        "#If you add \"index\" as \"False\", it will move the Patient ID to row names. If you name the index \"True\" it will add patient Id the 1st column."
      ],
      "metadata": {
        "id": "2ovXa3TPlFPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List the row names of df_2 dataframe\n",
        "list(df_2.index.values)"
      ],
      "metadata": {
        "id": "OzNnZc_Gt0ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cancer_TorF.csv must use the same Patient_ID values as its index column.\n",
        "#Import .csv file \"Cancer_TorF.csv\" as the new dataframe(df_Cancer_TorF) which has the column \"Cancer\" and data values \"T\" or \"F\". Only uppercase T/F are allowed in csv file\n",
        "#Set 1st column as the row name by \"index_col=0\".\n",
        "df_Cancer_TorF = pd.read_csv('Cancer_TorF.csv', index_col=0)\n",
        "df_Cancer_TorF.head()"
      ],
      "metadata": {
        "id": "Amq4-fl6vkUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the shape of the \"df_Cancer_TorF\" dataframe\n",
        "df_Cancer_TorF.shape"
      ],
      "metadata": {
        "id": "vlcKgX0oxyDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Give df_2 as the first dataframe to merge and df_1 as the second datframe to merge. This will bring \"Cancer\" column as the 1st column in new datframe df_3\n",
        "#Join \"df_Cancer_TorF\" and \"df_2\" dataframes using concatenate funchion\n",
        "df_3 = pd.concat([df_Cancer_TorF, df_2], axis=1)\n",
        "df_3.head()"
      ],
      "metadata": {
        "id": "Apy93Gev0AAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the shape of the \"df_Cancer_TorF\" dataframe\n",
        "df_3.shape"
      ],
      "metadata": {
        "id": "6affopqAawsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace output column \"Cancer\" with T=1 and F=0\n",
        "df_3['Cancer'] = df_3['Cancer'].str.replace('T','1')\n",
        "df_3['Cancer'] = df_3['Cancer'].str.replace('F','0')\n",
        "df_3.head()"
      ],
      "metadata": {
        "id": "-2rESMBW3-lm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To convert \"Cancer\" Column data in to numeric variable\n",
        "#To get the data types\n",
        "df_3['Cancer'] = pd.to_numeric(df_3['Cancer'])\n",
        "df_3.dtypes"
      ],
      "metadata": {
        "id": "pswUZEJlBNL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the Final Dataframe (df_3) as a backup.\n",
        "df_3.to_csv('General_MODEL_1_Final.csv', index= False)"
      ],
      "metadata": {
        "id": "7WWNqF8g3IOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Formating data set to 'X' variable. As for the convention use capital \"X\" for independent variables.\n",
        "X = df_3.drop('Cancer',axis=1).copy()\n",
        "X.head()"
      ],
      "metadata": {
        "id": "9Ld9EFSiBepe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Formating data set to 'y' variable. As for the convention use simple \"y\" for predicter variables.\n",
        "y = df_3['Cancer'].copy()\n",
        "y.head()"
      ],
      "metadata": {
        "id": "nvCFyXvJBrks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To veryfy that 'y' only contain 1s and 0s\n",
        "y.unique()"
      ],
      "metadata": {
        "id": "lTl_qn9vCDwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"y\" sample counts\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "WzYkqzcJQrkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To see what percentage of people have Cancer in the dataset.\n",
        "#Since \"y\" contain numbers (1 and 0), the sum function will calculate the number of cancer patients and len function will calculate the total rows.\n",
        "#Dividing number of patients by total number of rows will give you total number of patients as a percentage.\n",
        "sum(y)/len(y)"
      ],
      "metadata": {
        "id": "OZn97PMhCFSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting datasets in to four variables (X_train, X_test, y_train, y_test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,train_size = 0.7, stratify=y)"
      ],
      "metadata": {
        "id": "0H8MtE_SCZav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"y_train\" sample counts\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "ahMfuyImjfkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"y_test\" sample counts\n",
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "kKElK_vkjmN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#So both 'X' and 'y' variables are previously split in to 4 groups.\n",
        "#For 'X' => X_train and X_test.\n",
        "#For 'y' => y_train and y_test.\n",
        "\n",
        "#To verify that using stratify worked as expected in \"y_train\" must have a values closer to original Cancer percentage.\n",
        "sum(y_train)/len(y_train)"
      ],
      "metadata": {
        "id": "5ivGK4rQCyXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To verify that using stratify worked as expected in \"y_test\" must also have a value closer to original Cancer percentage\n",
        "sum(y_test)/len(y_test)"
      ],
      "metadata": {
        "id": "D8_0LSjtDOEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the best value for scaling the weights (Scale_pos_weight)\n",
        "# y.value_counts()\n",
        "# y_train.value_counts()\n",
        "\n",
        "# This parameter shows the data imbalance in the training set (Cancer and healthy)\n",
        "\n",
        "scale_pos_weight = y_train[y_train==0].count() / y_train[y_train==1].count()\n",
        "print(scale_pos_weight)\n"
      ],
      "metadata": {
        "id": "pZwonN262Awe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate column names in X variable\n",
        "duplicate_columns = X_train.columns[X_train.columns.duplicated()]\n",
        "if not duplicate_columns.empty:\n",
        "    print(\"Duplicate column names:\", duplicate_columns)"
      ],
      "metadata": {
        "id": "sZSquEy-vcKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost Default Parameters\n",
        "clf_xgb = xgb.XGBClassifier(seed=42,\n",
        "                            early_stopping_rounds=10,\n",
        "                            eval_metric='aucpr',\n",
        "                            base_score=0.5,\n",
        "                            booster='gbtree',\n",
        "                            colsample_bylevel=1,\n",
        "                            colsample_bynode=1,\n",
        "                            colsample_bytree=1,\n",
        "                            enable_categorical=False,\n",
        "                            device = \"cuda\", #Change device=\"cuda\" to device=\"cpu\" if GPU is unavailable\n",
        "                            importance_type=None,\n",
        "                            interaction_constraints='',\n",
        "                            objective='binary:logistic',\n",
        "                            gamma=0,\n",
        "                            learning_rate=0.3,\n",
        "                            max_depth=6,\n",
        "                            max_delta_step=0,\n",
        "                            reg_lambda=1,\n",
        "                            scale_pos_weight=1,\n",
        "                            min_child_weight=1,\n",
        "                            subsample=1,\n",
        "                            n_estimators=100,\n",
        "                            num_parallel_tree=1,\n",
        "                            reg_alpha=0,\n",
        "                            #tree_method='auto',\n",
        "                            tree_method='hist', #When using Colab GPU\n",
        "                            validate_parameters=1\n",
        "                            )\n",
        "clf_xgb.fit(X_train,\n",
        "            y_train,\n",
        "            verbose=True,\n",
        "            eval_set=[(X_test, y_test)])"
      ],
      "metadata": {
        "id": "Qc7RgpiB9UCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Best Validation score from above model\n",
        "print(\"Best validation score: \", clf_xgb.best_score)"
      ],
      "metadata": {
        "id": "FsI0L26ACEIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #predicting the ranbdomly selected test data (X_test) using the our created model. Just like the Final Exam\n",
        "clf_xgb.predict(X_test)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = clf_xgb.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "#evaluate predictions train vs test data\n",
        "accuracy = balanced_accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
      ],
      "metadata": {
        "id": "dxv9SMFjCT0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from scipy.stats import uniform, randint\n",
        "\n",
        "# # The parameter ranges in param_dist now reflect distributions from which values will be randomly sampled. For discrete parameters like max_depth, randint is used.\n",
        "# # For continuous parameters, uniform is used, where uniform(a, b) samples values over the range [a, a+b].\n",
        "# # The n_iter parameter in RandomizedSearchCV controls how many random combinations of parameters will be tried.\n",
        "# # Adjust it based on your computational resources and how exhaustive you want the search to be.\n",
        "\n",
        "\n",
        "\n",
        "# # Define the parameter distribution\n",
        "# param_dist = {\n",
        "#     'max_depth': randint(5,7),  # range you prefer , if it is 3-6 you should type as (3, 7) As upper boundary is exclusive\n",
        "#     'learning_rate': uniform(0.3, 0.3),  # Continuous distribution from [a, a+b]\n",
        "#     #'gamma': uniform(0, 0.1),  # Continuous distribution from [a, a+b]\n",
        "#     'reg_lambda': uniform(1.0, 5.0),  # Continuous distribution from [a, a+b]\n",
        "#     'scale_pos_weight': uniform(1, 0.5)  # Continuous distribution from [a, a+b]\n",
        "# }\n",
        "\n",
        "# # Initialize XGBoost Classifier\n",
        "# clf_xgb = xgb.XGBClassifier(seed=42,\n",
        "#                             eval_metric='aucpr',\n",
        "#                             base_score=0.5,\n",
        "#                             booster='gbtree',\n",
        "#                             colsample_bylevel=1,\n",
        "#                             colsample_bynode=1,\n",
        "#                             colsample_bytree=1,\n",
        "#                             enable_categorical=False,\n",
        "#                             device = \"cuda\", #Change device=\"cuda\" to device=\"cpu\" if GPU is unavailable\n",
        "#                             gamma=0,\n",
        "#                             importance_type=None,\n",
        "#                             interaction_constraints='',\n",
        "#                             objective='binary:logistic',\n",
        "#                             n_estimators=100,\n",
        "#                             n_jobs=50,\n",
        "#                             num_parallel_tree=1,\n",
        "#                             reg_alpha=0,\n",
        "#                             tree_method='hist',  # Use 'hist' for Colab GPU\n",
        "#                             validate_parameters=1)\n",
        "\n",
        "# # Initialize Randomized Search\n",
        "# random_search = RandomizedSearchCV(clf_xgb,\n",
        "#                                     param_distributions=param_dist,\n",
        "#                                     n_iter=200,  # Number of parameter settings that are sampled\n",
        "#                                     cv=5,\n",
        "#                                     scoring='average_precision',\n",
        "#                                     verbose=2,\n",
        "#                                     n_jobs=-1,\n",
        "#                                     random_state=42)\n",
        "\n",
        "# # Fit the data to RandomizedSearchCV (this will take some time depending on the number of iterations)\n",
        "# random_search.fit(X_train, y_train, eval_set=[(X_train, y_train)], early_stopping_rounds=15)\n",
        "\n",
        "# # Get the best parameters\n",
        "# print(\"Best parameters found: \", random_search.best_params_)\n"
      ],
      "metadata": {
        "id": "GhO461f_rN_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # The output shows the rank, mean test score, standard deviation of the test score, and the specific parameters for each of the top 5 parameter sets.\n",
        "\n",
        "# # Convert the cv_results to a DataFrame for easier sorting and manipulation\n",
        "# cv_results_df = pd.DataFrame(random_search.cv_results_)\n",
        "\n",
        "# # Sort the results by the mean test score, in descending order\n",
        "# sorted_cv_results_df = cv_results_df.sort_values(by='rank_test_score')\n",
        "\n",
        "# # Print the top 5 parameter sets\n",
        "# top_5_results = sorted_cv_results_df.head(5)\n",
        "\n",
        "# print(\"Top 5 parameter sets:\")\n",
        "# for index, row in top_5_results.iterrows():\n",
        "#     print(\"\\nRank:\", row['rank_test_score'])\n",
        "#     print(\"Mean Test Score:\", row['mean_test_score'])\n",
        "#     print(\"Std Test Score:\", row['std_test_score'])\n",
        "#     print(\"Parameters:\", row['params'])"
      ],
      "metadata": {
        "id": "EQi2oV-RwiZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Please note that the nested learning_rate / reg_lambda search may take a long time and it is optional.\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# Define your learning rates and reg_lambda values\n",
        "# learning_rates = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
        "\n",
        "learning_rates = [0.05, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
        "                  0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n",
        "                  0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65]\n",
        "\n",
        "reg_lambdas = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Nested loop over both hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for reg_lambda in reg_lambdas:\n",
        "        print(f\"\\n===== Training with learning_rate = {lr}, reg_lambda = {reg_lambda} =====\")\n",
        "\n",
        "        clf_xgb = xgb.XGBClassifier(\n",
        "            seed=42,\n",
        "            early_stopping_rounds=15,\n",
        "            eval_metric='aucpr',\n",
        "            base_score=0.5,\n",
        "            booster='gbtree',\n",
        "            colsample_bylevel=1,\n",
        "            colsample_bynode=1,\n",
        "            colsample_bytree=1,\n",
        "            enable_categorical=False,\n",
        "            device=\"cuda\", #Change device=\"cuda\" to device=\"cpu\" if GPU is unavailable\n",
        "            importance_type=None,\n",
        "            interaction_constraints='',\n",
        "            objective='binary:logistic',\n",
        "            gamma=0,\n",
        "            learning_rate=lr,\n",
        "            max_depth=6,\n",
        "            max_delta_step=0,\n",
        "            reg_lambda=reg_lambda,\n",
        "            scale_pos_weight=1,\n",
        "            min_child_weight=1,\n",
        "            subsample=1,\n",
        "            n_estimators=100,\n",
        "            n_jobs=50,\n",
        "            num_parallel_tree=1,\n",
        "            reg_alpha=0,\n",
        "            tree_method='hist',\n",
        "            validate_parameters=1\n",
        "        )\n",
        "\n",
        "        clf_xgb.fit(X_train, y_train, verbose=True, eval_set=[(X_test, y_test)])\n",
        "\n",
        "        best_val_score = clf_xgb.best_score\n",
        "        y_pred = clf_xgb.predict(X_test)\n",
        "        predictions = [round(value) for value in y_pred]\n",
        "        accuracy = balanced_accuracy_score(y_test, predictions)\n",
        "\n",
        "        print(\"Best validation score: \", best_val_score)\n",
        "        print(\"Balanced Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "        # Save results\n",
        "        results.append({\n",
        "            \"learning_rate\": lr,\n",
        "            \"reg_lambda\": reg_lambda,\n",
        "            \"best_val_score\": best_val_score,\n",
        "            \"balanced_accuracy\": accuracy\n",
        "        })\n"
      ],
      "metadata": {
        "id": "-LnVr2PheskF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Save results\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"results.csv\", index=False)\n",
        "\n",
        "# Trigger download (for Colab)\n",
        "files.download(\"results.csv\")\n"
      ],
      "metadata": {
        "id": "kuO5MCCycHLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Re-load the saved CSV\n",
        "# results_df = pd.read_csv(\"results.csv\")\n",
        "\n",
        "# # Convert DataFrame back to list of dicts\n",
        "# results = results_df.to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "Imeqnk5Rc28c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Sort all results by balanced accuracy (descending), then by validation score (descending)\n",
        "sorted_results = sorted(results, key=lambda r: (r[\"balanced_accuracy\"], r[\"best_val_score\"]), reverse=True)\n",
        "\n",
        "# Step 2: Take the top 5\n",
        "top_5_results = sorted_results[:5]\n",
        "\n",
        "# Step 3: Print them\n",
        "print(\"🏆 Top 5 Results by Balanced Accuracy (tie-breaker: validation score):\")\n",
        "for i, res in enumerate(top_5_results, 1):\n",
        "    print(f\"\\n🔹 Rank #{i}\")\n",
        "    print(f\"Learning Rate: {res['learning_rate']}\")\n",
        "    print(f\"Reg Lambda: {res['reg_lambda']}\")\n",
        "    print(f\"Balanced Accuracy: {res['balanced_accuracy'] * 100:.2f}%\")\n",
        "    print(f\"Validation Score: {res['best_val_score']:.4f}\")\n"
      ],
      "metadata": {
        "id": "hu5pdDD2KjdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modify the following Final MODEL according to the final results obtained form previous hyperparameters search.\n",
        "#XGBoost Final Model With Best Parameters\n",
        "clf_xgb = xgb.XGBClassifier(seed=42,\n",
        "                            early_stopping_rounds=15,\n",
        "                            eval_metric='aucpr',\n",
        "                            base_score=0.5,\n",
        "                            booster='gbtree',\n",
        "                            colsample_bylevel=1,\n",
        "                            colsample_bynode=1,\n",
        "                            colsample_bytree=1,\n",
        "                            enable_categorical=False,\n",
        "                            device = \"cuda\", #Change device=\"cuda\" to device=\"cpu\" if GPU is unavailable\n",
        "                            importance_type=None,\n",
        "                            interaction_constraints='',\n",
        "                            objective='binary:logistic',\n",
        "                            gamma=0,\n",
        "                            learning_rate=0.3,\n",
        "                            max_depth=6,\n",
        "                            max_delta_step=0,\n",
        "                            reg_lambda=1,\n",
        "                            scale_pos_weight=1,\n",
        "                            min_child_weight=1,\n",
        "                            subsample=1,\n",
        "                            n_estimators=100,\n",
        "                            n_jobs=50,\n",
        "                            num_parallel_tree=1,\n",
        "                            reg_alpha=0,\n",
        "                            #tree_method='auto',\n",
        "                            tree_method='hist', #When using Colab GPU\n",
        "                            validate_parameters=1\n",
        "                            )\n",
        "clf_xgb.fit(X_train,\n",
        "            y_train,\n",
        "            verbose=True,\n",
        "            eval_set=[(X_test, y_test)])"
      ],
      "metadata": {
        "id": "qUNIs6GfLaTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Best Validation score from above model\n",
        "print(\"Best validation score: \", clf_xgb.best_score)"
      ],
      "metadata": {
        "id": "kyqlO_s9jFzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #predicting the ranbdomly selected test data (X_test) using the our created model. Just like the Final Exam\n",
        "clf_xgb.predict(X_test)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = clf_xgb.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "#evaluate predictions train vs test data\n",
        "accuracy = balanced_accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "1qHETJE0Mr4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "# Predict probabilities for class 1\n",
        "y_proba = clf_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "aucpr = average_precision_score(y_test, y_proba)\n",
        "aucroc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# Print results\n",
        "print(f\"Average Precision Score (AUC-PR) on test set: {aucpr:.4f}\")\n",
        "print(f\"ROC AUC Score on test set: {aucroc:.4f}\")\n"
      ],
      "metadata": {
        "id": "EeZOGOD8XcmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print the Final hyperparameters used for record\n",
        "params = clf_xgb.get_params()\n",
        "for key, value in params.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "KeE8YLkA6CrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# clf_xgb is your trained model and X_test is your test dataset\n",
        "predictions = clf_xgb.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "id": "dboIhNFnWedh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# List of CV values to try\n",
        "cv_values = [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Collect results\n",
        "cv_results_summary = []\n",
        "\n",
        "# Get XGBoost core parameters from a pre-trained model\n",
        "xgb_params = clf_xgb.get_xgb_params()\n",
        "xgb_params['eval_metric'] = 'aucpr'\n",
        "\n",
        "# Create DMatrix\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "# Loop over different CV folds\n",
        "for cv in cv_values:\n",
        "    print(f\"\\n🔁 Running CV with {cv}-folds\")\n",
        "\n",
        "    results = xgb.cv(\n",
        "        params=xgb_params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=1000,\n",
        "        nfold=cv,\n",
        "        stratified=True,\n",
        "        early_stopping_rounds=15,\n",
        "        seed=42,\n",
        "        verbose_eval=False  # Change to True if you want step-by-step logs\n",
        "    )\n",
        "\n",
        "    best_score = results['test-aucpr-mean'].max()\n",
        "    best_iteration = results['test-aucpr-mean'].idxmax()\n",
        "\n",
        "    print(f\"CV = {cv} | Best AUC-PR: {best_score:.4f} at round {best_iteration}\")\n",
        "\n",
        "    # Save result\n",
        "    cv_results_summary.append({\n",
        "        \"cv\": cv,\n",
        "        \"best_aucpr\": best_score,\n",
        "        \"best_iteration\": best_iteration\n",
        "    })\n"
      ],
      "metadata": {
        "id": "oQ449qNmWXxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Find the highest AUC-PR value\n",
        "max_aucpr = max(r[\"best_aucpr\"] for r in cv_results_summary)\n",
        "\n",
        "# Step 2: Get all CV configs that reached the highest AUC-PR\n",
        "top_cv_configs = [r for r in cv_results_summary if r[\"best_aucpr\"] == max_aucpr]\n",
        "\n",
        "# Step 3: Pick the one with the smallest CV (or change this tie-breaker)\n",
        "best_cv_result = min(top_cv_configs, key=lambda x: x[\"cv\"])\n",
        "\n",
        "# Step 4: Print result\n",
        "print(\"🏆 Best AUC-PR across CV folds:\")\n",
        "print(f\"CV folds: {best_cv_result['cv']}\")\n",
        "print(f\"AUC-PR: {best_cv_result['best_aucpr']:.4f}\")\n",
        "print(f\"Boosting rounds: {best_cv_result['best_iteration']}\")\n"
      ],
      "metadata": {
        "id": "07e8yS1KWYMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Get core XGBoost parameters (not sklearn-style)\n",
        "xgb_params = clf_xgb.get_xgb_params()\n",
        "xgb_params['eval_metric'] = 'aucpr'  # Make sure AUC-PR is used\n",
        "\n",
        "# Create DMatrix\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "#Make sure to add the best \"CV folds\" number obtained from the above CV result here \"nfold=8\"\n",
        "# Perform K-fold cross-validation\n",
        "cv_results = xgb.cv(\n",
        "    params=xgb_params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    nfold=8,\n",
        "    stratified=True,\n",
        "    early_stopping_rounds=15,\n",
        "    seed=42,\n",
        "    verbose_eval=True\n",
        ")\n",
        "\n",
        "print(cv_results)\n"
      ],
      "metadata": {
        "id": "CI-oFsBCvwba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print CV score from the best iteration.\n",
        "best_aucpr = cv_results['test-aucpr-mean'].max()\n",
        "print(\"Best AUCPR Score from Cross Validation:\", best_aucpr)\n"
      ],
      "metadata": {
        "id": "WeZmYqOgPZSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming cv_results is the result from xgb.cv\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "\n",
        "# Display the results in a table\n",
        "print(cv_results_df)\n",
        "\n",
        "# Plot the training and testing mean AUCPR scores with specified figsize\n",
        "ax = cv_results_df[['test-aucpr-mean', 'train-aucpr-mean']].plot(figsize=(6.5, 4.5))\n",
        "plt.title('XGBoost Cross-Validation Results')\n",
        "plt.xlabel('Number of boosting rounds')\n",
        "plt.ylabel('AUCPR')\n",
        "\n",
        "# Add a dotted line at the highest AUCPR\n",
        "highest_aucpr = cv_results_df['test-aucpr-mean'].max()\n",
        "plt.axhline(y=highest_aucpr, color='r', linestyle='--', label=f\"Max AUCPR: {highest_aucpr:.4f}\")\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Save the plot as PNG and PDF\n",
        "ax.figure.savefig('XGBoost Cross Validation Results.png', bbox_inches='tight')\n",
        "ax.figure.savefig('XGBoost Cross Validation Results.pdf', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "kUXrz-5vP1Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct way to get best round from CV:\n",
        "best_round = cv_results['test-aucpr-mean'].idxmax()\n",
        "print(\"Best round from CV:\", best_round)\n"
      ],
      "metadata": {
        "id": "owuupY4O4zAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract feature importances from the model\n",
        "importances = clf_xgb.get_booster().get_score(importance_type='gain')\n",
        "\n",
        "# Sort features based on importance\n",
        "sorted_features = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Save top 100 features to a txt file\n",
        "with open('top_100_features.txt', 'w') as f:\n",
        "    for feature, importance in sorted_features[:100]:\n",
        "        f.write(f\"{feature}: {importance}\\n\")\n",
        "\n",
        "# Set the size of the plot\n",
        "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
        "\n",
        "# Plot the top 20 most important features\n",
        "plot_importance(clf_xgb, max_num_features=20, importance_type='gain')\n",
        "\n",
        "# Add labels and a title\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('F Score')\n",
        "plt.ylabel('Features')\n",
        "\n",
        "# Save the Feature Importance figure as a PDF\n",
        "plt.savefig('xgb_feature_importance.pdf', dpi=300)\n",
        "\n",
        "# Save the Feature Importance figure as a PNG\n",
        "plt.savefig('xgb_feature_importance.png', dpi=300)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dZQ9Y_gvvjYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Ensure the model is a binary classifier\n",
        "assert len(clf_xgb.classes_) == 2, \"Model is not a binary classifier\"\n",
        "\n",
        "# Get probabilities for the positive class\n",
        "y_preds = clf_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_preds)\n",
        "\n",
        "# Calculate AUC (Area under the ROC Curve )\n",
        "auc_score = metrics.auc(fpr, tpr)\n",
        "\n",
        "# Create figure and axis\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.plot(fpr, tpr, color='blue', label='ROC curve (area = {:.2f})'.format(auc_score))\n",
        "\n",
        "# Plot the line of no discrimination\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "\n",
        "# Set plot labels and title\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "\n",
        "# Add legend\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Save the ROC curve as a PNG\n",
        "plt.savefig('cfdna_xgb_ROC.png', dpi=300)\n",
        "\n",
        "# Save the ROC curve as a PDF\n",
        "plt.savefig('cfdna_xgb_ROC.pdf', dpi=300)\n",
        "\n",
        "# # Show the plot\n",
        "plt.show()\n",
        "\n",
        "# # Close the plot\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "P0IplU4-lZlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Save the BEST XGBoost tree at the best iteration.\n",
        "# Assuming you've already trained your XGBoost model with early stopping and clf_xgb is your trained model\n",
        "\n",
        "# Get the best iteration (subtracting 1 because it's 0-indexed)\n",
        "#best_iteration = clf_xgb.best_ntree_limit - 1\n",
        "best_iteration = clf_xgb.best_iteration\n",
        "\n",
        "\n",
        "# Set parameters for the nodes in the graph\n",
        "node_params = {'shape': 'box',  # Make the nodes fancy\n",
        "               'style': 'filled, rounded',\n",
        "               'fillcolor': '#78cbe'}\n",
        "\n",
        "# Set parameters for the leaf nodes in the graph\n",
        "leaf_params = {'shape': 'box',  # Make the nodes fancy\n",
        "               'style': 'filled',\n",
        "               'fillcolor': '#e48038'}\n",
        "\n",
        "# Generate the graph for the best iteration\n",
        "graph = xgb.to_graphviz(clf_xgb, num_trees=best_iteration, size=\"10,10\",\n",
        "                        condition_node_params=node_params,\n",
        "                        leaf_node_params=leaf_params)\n",
        "\n",
        "# Save the graph to a PDF file\n",
        "graph.format = 'pdf'\n",
        "graph.render('best_tree_graph')\n",
        "\n",
        "# Display the tree\n",
        "graph.view(cleanup=True)\n"
      ],
      "metadata": {
        "id": "J8I1lGKcD8ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To print the BEST XGBoost tree\n",
        "\n",
        "bst =clf_xgb.get_booster()\n",
        "for importance_type in ('weight','gain','cover','total_gain','total_cover'):\n",
        "  print('%s:'% importance_type, bst.get_score(importance_type=importance_type))\n",
        "\n",
        "node_params = {'shape':'box', ##make the nodes fancy\n",
        "               'style':'filled, rounded',\n",
        "               'fillcolor':'#78cbe'}\n",
        "\n",
        "leaf_params = {'shape':'box', ##make the nodes fancy\n",
        "               'style':'filled',\n",
        "               'fillcolor':'#e48038'}\n",
        "\n",
        "xgb.to_graphviz(clf_xgb, num_trees=best_iteration,size=\"14,14\",\n",
        "                 condition_node_params=node_params,\n",
        "                 leaf_node_params=leaf_params)"
      ],
      "metadata": {
        "id": "M_FmJUJt7dwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = clf_xgb.predict(X_test)\n",
        "\n",
        "# Generate confusion matrix from predictions\n",
        "disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=[\"Healthy\",\"Cancer\"])\n",
        "\n",
        "# Add a title to the plot\n",
        "plt.title('Confusion Matrix Cancer VS Healthy')\n",
        "\n",
        "# Save the plot to a PDF file\n",
        "plt.savefig('confusion_matrix.pdf', format='pdf', bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ewywh3rZsVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install SHAP if not installed\n",
        "!pip install shap\n",
        "\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a SHAP explainer object and calculate SHAP values for the training set\n",
        "explainer = shap.TreeExplainer(clf_xgb)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Convert SHAP values to a Pandas DataFrame\n",
        "shap_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
        "\n",
        "# =================== Save SHAP values for ALL features (Commented Out) ===================\n",
        "# shap_csv_output_all = \"SHAP_values_all_features.csv\"\n",
        "# shap_df.to_csv(shap_csv_output_all, index=False)\n",
        "# print(f\"SHAP values for all features saved as: {shap_csv_output_all}\")\n",
        "\n",
        "# Identify the top 20 most important features based on mean absolute SHAP values\n",
        "shap_importance = np.abs(shap_df).mean().sort_values(ascending=False)\n",
        "top_20_features = shap_importance.index[:20]\n",
        "\n",
        "# Filter only the top 20 features\n",
        "shap_df_top20 = shap_df[top_20_features]\n",
        "\n",
        "# Save SHAP values for the top 20 features to a CSV file\n",
        "shap_csv_output_top20 = \"SHAP_values_top20_features.csv\"\n",
        "shap_df_top20.to_csv(shap_csv_output_top20, index=False)\n",
        "print(f\"SHAP values for top 20 features saved as: {shap_csv_output_top20}\")\n",
        "\n",
        "# Set up the matplotlib figure for the summary plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(shap_values, X_train, show=False)\n",
        "plt.title(\"SHAP Summary Plot for Model Features\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure to a PDF\n",
        "pdf_output_summary = \"SHAP_summary_plot.pdf\"\n",
        "plt.savefig(pdf_output_summary, format='pdf')\n",
        "\n",
        "# Display the SHAP summary plot in the notebook\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PX-Vpmk-03mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_scores = clf_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "# Compute the precision and recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label='XGBoost')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mebtXR0KBICG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Zip the directory where your files are saved and download all at once\n",
        "# !zip -r output_files.zip /content/\n",
        "# from google.colab import files\n",
        "# files.download(\"output_files.zip\")"
      ],
      "metadata": {
        "id": "Iisx8GUGPALy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import sklearn\n",
        "import matplotlib\n",
        "import shap\n",
        "\n",
        "packages = {\n",
        "    'pandas': pd.__version__,\n",
        "    'numpy': np.__version__,\n",
        "    'xgboost': xgb.__version__,\n",
        "    'scikit-learn': sklearn.__version__,\n",
        "    'matplotlib': matplotlib.__version__,\n",
        "    'shap': shap.__version__\n",
        "}\n",
        "\n",
        "print(packages)\n"
      ],
      "metadata": {
        "id": "KgY5cSQoQwDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #To list all the attributes of your clf_xgb object\n",
        "dir(clf_xgb)"
      ],
      "metadata": {
        "id": "G5YU2IqrLGaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created by: Sakuntha Devaka Gunarathna /\n",
        "Published Date: July 30, 2025"
      ],
      "metadata": {
        "id": "e1H_PMwoth9K"
      }
    }
  ]
}